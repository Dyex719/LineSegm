ELABORATO TDBD


- aggiungere colonna time a tabelle
- aggiungere tabella autori
- commentare esperimenti
- confrontare risultati
- immagine con path zommata
- immagine con confronto detected groundtruth, corretto e sbagliato, didascalia con misure


<listOptionValue builtIn="false" value="__GXX_EXPERIMENTAL_CXX0X__"/>
<listOptionValue builtIn="false" value="__cplusplus=201103L"/>


<listOptionValue builtIn="false" value="opencv_imgproc"/>
<listOptionValue builtIn="false" value="opencv_core"/>
<listOptionValue builtIn="false" value="opencv_highgui"/>
<listOptionValue builtIn="false" value="opencv_imgcodecs"/>

errori
55, 50, 20, 14


results:

- heu 5 step 2 sg: 94.08 98.85 95.2 1339 1431
- heu 10 step 2 sg: 94.10 98.30 96.9 1339 1431
- heu 10 step 1 sg: 94.13 98.9 95.03 1340 1431 4646
- heu 20 step 1 sg: 94.13 98.9 95.03 1340 1431 2352

- heu 5 step 2 mls: 85.2 93.4 90 144 200
- heu 10 step 2 mls: 85.3 93.4 90 144 200
- heu 20 step 1 mls: 85.4 93.5 90 144 200 2474

esperimenti:

- 5, 2, open
- 5, 2, close
- 10, 2, open
- 10, 2, close
- 10, 1, open
- 10, 1, close
- 20, 1, open
- 20, 1, close

- IMMAGINI:
    - esempio per i due dataset
    - confronto normale, otsu, sauvola
    - immagine istogramma proiezione line localization, messo sopra immagine binarizzata da cui è estratto
    - esempio di path per entrambi i dataset, due immagini tot
    - esempio di grountruth e corrispondente linea segmentata
    - tabella statistiche, magari istogramma


- INTRODUZIONE
Parlare dei progressi nel riconoscimento automatico di testo scritto a mano. Importante perchè tante informazioni non sono digitalizzate. Uno dei primi passi è trovare e segmentare le linee di un testo manoscritto, in modo poi da sottoporre le singole linee ad un ulteriore processing dove verranno trovate le parole e digitalizzate ecc. Questo elaborato prevede l'utilizzo di una tecnica per la segmentazione di testo manoscritto sfruttando le capacità dell'a star, un algoritmo di pathfinding. Le fasi per processare una pagina di un testo manoscritto sono tre: binarizzazione, localizzazione delle linee all'interno della pagina ed infine esecuzione dell'algoritmo di pathfinding.

- SAUVOLA
La prima fase prevede di binarizzare l'immagine che rappresenta la pagina di testo manoscritto. I testi dei dataset usati contengono immagini, inchiostro che si vede dalla pagina sotto ecc, e quindi le normali tecniche di binarizzazione non funzionano al meglio. In particolare, una delle tecniche più usate, otsu, lascia tracce dell'inchiosto che si vede dalla pagina sotto. Per questo motivo è stata implementata la tecnica di sauvola per la binarizzazione. Una finestra, in genere 20x20, viene fatta scorrere lungo l'immagine, con step 1. Per ciascuna finestra viene calcolata la media e la deviazione standard. Otterrò così due matrici di dimensioni pari all'immagine originale, i cui valori sono la media e la std dei pixel che erano centrati nella finestra. Grazie a questi valori, posso sogliare dinamicamente e in maniera indipendente l'immagine originale, tenendo così conto delle differenza fra le varie zone, anche piccole, dell'immagini. Mostrare risultati comparativi fra otsu e sauvola. Parlare dei dettagli implementativi: usato c++, immagini integrali, formula per la sogliatura, soglia usata.

- LINE LOCALIZATION
La seconda fase riguarda la localizzazione delle line di testo all'interno della pagina (immagine). In particolare quello che interessa è la posizione sull'asse delle ordinate della linea di testo. Per fare ciò si usa la projection profile analysis. Prendo la mia immagine, inverto l'immagine, metto i valori che prima erano 0 o 255, a 0 o 1, sommo le righe della matrice corrispondente orizzontalmente, ottengo così un istogramma verticale che mi indica dove sono concentrati i pixel neri. A questo punto si tratta di utilizzare tecniche di peak detection per rilevari i picchi dell'istogramma, scegliendo una soglia opportuna (alcune line sono lunghe, valori istogramma alto, altre corte, valori istogramma più basso). Una volta trovati i picchi, questi mi rappresentano la coordinata y dell'inizio della linea di testo. Tuttavia, siccome la segmentazione delle linee viene fatta nello spazio bianco fra di linee di testo, quello che ci interressa sono i punti fra due picchi, che rappresentano una valle, ovvero uno spazio bianco fra due linee di testo. Dettaglia implementativi: c++, apertura per rendere più corpose le linee, uso della libreria persistance1D.hpp per peak detection, scelta della soglia.

- ASTAR
Una volta trovati i punti di partenza da cui segmentare, posso usare astar. Lo start node è il punto di coordinata y calcolata dalla line localization e di coordinata x pari a 0; il goal node ha la stessa coordinata y di start ma coordinata x pari all'ultima colonna dell'immagine. Astar funziona così: partendo dallo start node, esploro i nodi vicini a questo e per ciascuno stimo un costo dato dal passo e da un euristica per stimare la distanza rimanente dall'end node. Ciascuno di questi vicini viene messo nell'open set. Poi viene selezionato il miglior nodo dell'open set, che viene rimosso da esso, e si ricomincia, calcolo vicini etc. Continuo finchè il nodo migliore che tiro fuori da open set non è uguale all'end node. A questo punto, essendomi salvato ogni volta il parente di ciascun nodo, ovvero il nodo precedente grazie al quale siamo arrivati a quel nodo, partendo dall'end node vado al contriario esaminando i parenti fino a ricostruirmi l'intero percorso fatto da astar. Al termine di astar, eseguito per ciascuan linea di testo nell'immagini, avrò segmentato il documento di testo manoscritto. Dettagli implementativi: una volta segmentata una riga questa viene salvata da solo su un'immagine a parte, così per tutte le righe, serve per confrontarsi col groundtruth; possibilità di stare uno stesso all'esplorazione dei vicini, 1 o 2, per accorciare i tempi dell'algoritmo; ricorso ad un'euristica non ammissibile ovvero che sovrastima la distanza rimasta fra nodo corrente e nodo finale in modo da velocizzare l'algoritmo; utilizzo di una coda di priorità per far si che l'estrazione del nodo col migliore score sia costante (non così per l'inserimento), parlare dei parametri usati per i due dataset, parlare delle funzioni di costo ad hoc per questo elaborato basate sull'articolo e cosa esse rappresentano, sottolineando la particolarità che questa implementazione di astar può, su necessità, attraversare gli ostacoli, ovvero il testo (fare un accenno a questa particolarità anche nell'introduzione essendo una caratteristica portante del paper).

- DATASET
Descrivere i due dataset usati. Saintgall, dire che tipo di testo manoscritto è da dove viene, chi l'ha creato etc. Dire che dimensioni hanno le immagini e quante sono, più particolarità varie. Monk Line Segmentation dataset, dire che tipo di documenti manoscritti contiene, da dove viene e chi l'ha creata, particolarità di questo dataset è la presenza di molti problemi della line segmentation, quante immagini, dimensioni varie poichè provenienti da diverse fonti.

- CREAZIONE GROUNDTRUTH
Per creare il grountruth della line segmentation è stato utilizzato uno script python che processa le varie immagini. Le immagini sono state croppate ad una dimensione uniforme, binarizzate e poi si è proceduto alla creazione del grountruth rappresentato da immagini contenenti una singola linea di testo binarizzato, di dimensioni pari all'immagine di riferimento e con la lista contestualmente nella posizione corretta. Per il dataset saintgall, per estrarre le singole linee sono stati sfruttati dei file xml dove per ciascuna immagine erano presenti le coordinate del contorno di ciascuna linea di testo. Facendo il parsing di tale documento è stato possibile creare il grountruth per saintgall. Per MLS, è stata scelta una selezione di 10 documenti, che rappresentasse pià o meno tutti i vari tipi di problemi e difficoltà, ed è stato creato il grountruth questa volta a mano, utilizzando uno strumento di disegno digitale tipo paint (gimp in particolare)

- ESPERIMENTI
Quindi preso un documento manoscritto, ho tante immagini quante sono le linee di testo, rappresentanti il grountruth, e tante immagini quante sono le linee di testo trovate dalla procedura. Queste vengono comparate utilizzando varie misure: pixel level hit rate, line detection GT e line detection detected. Spiegare a modo cosa significano queste misure, le soglie, e come si calcolano. Si calcolano sovrapponendo le immagini e confrontanto i pixel che si sovrappongono ecc. Dire quanto una linea di testo è correttamente detected.
Discutere i risultati ottenuti sui due dataset variano: step, ammissibilità euristica e confrontando precisione dei risultati e velocità dell'esecuzione.

- CONCLUSIONE
Parlare dei risultati e dei problemi. Dire se i risultati sono soddisfacenti, soprattutto in confronto con gli autori del paper.
I problemi sono:
- binarizzazione con sauvola meglio di otsu, ma non precisa con disegni nel testo come quelli dei manoscritti antici; inoltre con la soglia scelta alcuni vengono troppo scuri esaltando il rumore con altre soglie viene troppo chiara ovvero viene mangiato un po' di testo, difficile trovare una soglia generale per tutte le situazione, in alcuni casi bisogna accettare una sogliatura non perfetta, se si vuole automatizzare il tutto.
- line localization non sempre precisa, linee di testo corte corrispondono a picchi bassi. la soglia scelta per trovare i picchi a volte porta ad escludere tali piccoli picchi, non trovando quindi la linea. Inoltre a volte trova picchi troppo vicini o non esattamente al centro del picco ma un po' più spostato.
- astar, lento per immagini molto grandi anche in c++ e accorgimenti vari. Miglioro con step, non ammissibilità, riducendo dimensioni immagini ma scendono a compromessi con la precisione della segmentazione.

